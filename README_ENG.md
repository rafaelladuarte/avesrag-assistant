# ğŸ¦œ AvesRAG â€“ Assistente de IdentificaÃ§Ã£o de Aves do Cerrado

![cover](docs/images/avesrag.jpg)

[![Python](https://img.shields.io/badge/Python-3.11%2B-blue?logo=python)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-App-FF4B4B?logo=streamlit\&logoColor=white)](https://streamlit.io/)
[![LLM](https://img.shields.io/badge/LLM-llama--3.1--8b--instant-green)](#)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> ğŸ† Project developed for the **LLM Zoomcamp** course from [DataTalks.Club](https://datatalks.club)

## ğŸ“Œ Problem

Existing bird identification applications generally work with photos or sounds. However, observers are not always able to capture an image or recording at the time of sighting.
In these situations, the only available reference is the visual description of the bird, such as color, size, beak shape, or behavior.
AvesRAG was created to address this exact scenario, allowing bird identification based on text descriptions.

## ğŸ“Œ About the Project

The **AvesRAG Assistant** is an interactive intelligent assistant that aims to solve this problem by identifying birds based on user-provided descriptions. Using the **RAG (Retrieval-Augmented Generation)** technique, it searches for information in a custom database and returns **up to 3 candidate species** with summarized descriptions.

---
## ğŸ–¼ Interface Preview

> *(Adicione aqui um print da aplicaÃ§Ã£o rodando)*

![preview](images/preview.png)

## ğŸ¯ Objectives

* Create an interactive tool for bird identification.
* Use RAG to combine structured search and text generation via LLM.
* Ensure the backend and pipeline are modular and easy to adapt.
* Collect user feedback to continuously improve results (In development).

## ğŸ“Š Database

The database used was created from:

* Integration of existing databases.
* Scraping from online sources.
* Data parameterization via LLM.


5.000 / 5.000
# ğŸ¦œ AvesRAG â€“ Bird Identification Assistant Cerrado

![cover](docs/images/avesrag.jpg)

[![Python](https://img.shields.io/badge/Python-3.11%2B-blue?logo=python)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-App-FF4B4B?logo=streamlit\&logoColor=white)](https://streamlit.io/)
[![LLM](https://img.shields.io/badge/LLM-llama--3.1--8b--instant-green)](#)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> ğŸ† Project developed for the course **LLM Zoomcamp** by [DataTalks.Club](https://datatalks.club)

## ğŸ“Œ Problem

Existing bird identification applications generally work with photos or sounds. However, observers are not always able to capture an image or recording at the time of sighting.
In these situations, the only available reference is the visual description of the bird, such as color, size, beak shape, or behavior.
AvesRAG was created to address this exact scenario, allowing bird identification based on text descriptions.

## ğŸ“Œ About the Project

The **AvesRAG Assistant** is an interactive intelligent assistant that aims to solve this problem by identifying birds based on user-provided descriptions. Using the **RAG (Retrieval-Augmented Generation)** technique, it searches for information in a custom database and returns **up to 3 candidate species** with summarized descriptions.

---
## ğŸ–¼ Interface Preview

> *(Add a screenshot of the application running here)*

![preview](images/preview.png)

## ğŸ¯ Objectives

* Create an interactive tool for bird identification.
* Use RAG to combine structured search and text generation via LLM.
* Ensure the backend and pipeline are modular and easy to adapt.
* Collect user feedback to continuously improve results (In development).

## ğŸ“Š Database

The database used was created from:

* Integration of existing databases.
* Scraping from online sources.
* Data parameterization via LLM.

ğŸ“‚ Database Builder Repository: [rafaelladuarte/avesrag-dataset-builder](https://github.com/rafaelladuarte/avesrag-dataset-builder)

## ğŸ§© System Architecture

```mermaid
flowchart LR
    A[UsuÃ¡rio] -->|DescriÃ§Ã£o da ave| B[Streamlit UI]
    B --> | ParamÃªtros | D[MinSearch - Busca SemÃ¢ntica + Vetorial]
    D --> | Documentos Recuperados | E[LLM - Groq API]
    E --> | Documentos Verificados | B
    B --> | ValidaÃ§Ã£o do Resultado | F[Feedback]
    F --> H[PostgresSQL]
    B --> G[Monitoramento- Em desenvolvimento]
    G --> H
    H --> | RelatÃ³rio com MÃ©tricas | B
```

## âœ¨ Features

âœ… Data entry via form with validation. \
âœ… Optimized search with MinSearch (semantic + textual). \
âœ… Return of **up to 3 candidate species**. \
âœ… Automatic species summary with images.\
âœ…  User feedback collection\
ğŸ”„ Monitoring LLM usage - API.

## ğŸ”¬ AvaliaÃ§Ã£o

### ğŸ” Retrieval

* **Testes realizados**:

  * BM25 (textual)
  * Vetorial (embeddings)
  * Busca hÃ­brida (melhor resultado)
* **Resultado**: busca hÃ­brida apresentou maior recall e precisÃ£o para descriÃ§Ãµes curtas.

### ğŸ§  LLM

* Avaliados diferentes modelos open-source.
  * `llama-3.1-8b-instant`
  * `gemma2-9b-it `
  * `deepseek-r1-distill-llama-70b`
* Testados prompts *zero-shot* vs *few-shot*.
* **Resultado**: `llama-3.1-8b-instant` com *few-shot* teve melhor equilÃ­brio entre custo e precisÃ£o.

## ğŸ“Š Feedback e Monitoramento (em desenvolvimento)

* Coleta de feedback de usuÃ¡rios (sim/nÃ£o sobre utilidade da resposta).
* Armazenamento em PostgreSQL
* Dashboard no Streamlit com mÃ©tricas:

  * NÂº de consultas
  * EspÃ©cies mais buscadas
  * Taxa de respostas aceitas
  * Tempo mÃ©dio de resposta

---
## ğŸ›  Tecnologias Utilizadas

| Categoria                | Ferramentas                                                                                                             |
| ------------------------ | ----------------------------------------------------------------------------------------------------------------------- |
| **Linguagem**            | Python 3.11+                                                                                                            |
| **Framework Web**        | [Streamlit](https://streamlit.io/)                                                                                      |
| **LLM (Assistente)**     | `llama-3.1-8b-instant`                                                                                                  |
| **LLMs (Base de dados)** | `gemma2-9b-it`, `deepseek-r1-distill-llama-70b`, `llama-3.1-8b-instant` |
| **Backend de Busca**     | [MinSearch](https://github.com/alexeygrigorev/minsearch) *(adaptado)*                                                   |
| **API LLM**              | [Groq API](https://groq.com/)                                                                                           |
| **Processamento**        | pandas, numpy                                                                                                           |
| **Controle de VersÃ£o**   | Git + GitHub                                                                                                            |

## ğŸ“‚ Estrutura do Projeto

```
ğŸ“¦ avesrag-assistant
ğŸ“¦ averag-assistant
â”œâ”€â”€ app.py                # Main application entry point
â”œâ”€â”€ dev.py                # Auxiliary script for local development and testing
â”œâ”€â”€ docs/                 # Project documentation
â”‚   â”œâ”€â”€ images/           # Images used in the documentation
â”‚   â””â”€â”€ notes/            # Notes, drafts, and references
â”œâ”€â”€ Pipfile               # Dependency definitions (Pipenv)
â”œâ”€â”€ Pipfile.lock          # Dependency lockfile (ensures reproducibility)
â”œâ”€â”€ requirements.txt      # Alternative dependency list for pip installation
â”œâ”€â”€ README.md             # Main documentation (Portuguese)
â”œâ”€â”€ README_ENG.md         # Main documentation (English)
â”œâ”€â”€ .gitignore            # Files and folders ignored by Git
â”œâ”€â”€ script/               # Scripts organized by domain
â”‚   â”œâ”€â”€ api/              # Code related to external API integration
â”‚   â”œâ”€â”€ data/             # Dataset used for RAG (in JSON format)
â”‚   â”œâ”€â”€ database/         # Database connection and operations
â”‚   â”œâ”€â”€ notebooks/        # Jupyter Notebooks for analysis and experiments
â”‚   â”œâ”€â”€ services/         # Streamlit interface scripts
â”‚   â””â”€â”€ utils/            # Helper functions and general utilities
â””â”€â”€ venv/                 # Python virtual environment (not versioned)
```

## âš™ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/usuario/avesrag-assistant.git
cd avesrag-assistant
```

### 2. Crie o ambiente virtual e instale dependÃªncias

```bash
python -m venv venv
source venv/bin/activate          # Linux/Mac
source venv\Scripts\activate      # Windows
pip install -r requirements.txt
```

### 3. Configure variÃ¡veis de ambiente

Crie um arquivo `.env` com:

```
GROQ_API_KEY="suachaveaqui"
POSTGRES_URL="suauriaqui"
```

### 4. Execute a aplicaÃ§Ã£o

```bash
streamlit run app.py
```

## ğŸ“ˆ CritÃ©rios de AvaliaÃ§Ã£o Atendidos

* [x] Problema descrito claramente
* [x] Knowledge base + LLM no fluxo
* [x] AvaliaÃ§Ã£o de mÃºltiplos retrieval flows
* [x] AvaliaÃ§Ã£o de diferentes prompts/modelos
* [x] Interface em Streamlit
* [ ] IngestÃ£o automatizada via scripts Python
* [ ] Monitoramento com feedback + dashboard
* [ ] ContainerizaÃ§Ã£o com Docker
* [x] Reprodutibilidade (instruÃ§Ãµes + requirements)

## ğŸ“ˆ PrÃ³ximos Passos

* ğŸ”§ Ajustar pesos e parÃ¢metros de busca no MinSearch
* ğŸ¦ Expandir base para mais espÃ©cies brasileiras
* ğŸ§ª Criar testes unitÃ¡rios e de integraÃ§Ã£o
* ğŸ“Š Adicionar logging e monitoramento de consultas


## ğŸ“œ LicenÃ§a

DistribuÃ­do sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.