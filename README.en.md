# ğŸ¦œ AvesRAG â€“ Bird Identification Assistant Cerrado

![cover](docs/images/avesrag.jpg)

[![Python](https://img.shields.io/badge/Python-3.11%2B-blue?logo=python)](https://www.python.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-App-FF4B4B?logo=streamlit\&logoColor=white)](https://streamlit.io/)
[![LLM](https://img.shields.io/badge/LLM-llama--3.1--8b--instant-green)](#)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> ğŸ† Project developed for the course **LLM Zoomcamp** by [DataTalks.Club](https://datatalks.club)

> > ğŸ‡§ğŸ‡· Este README tambÃ©m estÃ¡ disponÃ­vel em [PortuguÃªs](README.md).

## ğŸ“Œ Problem

Existing bird identification applications generally work with photos or sounds. However, observers are not always able to capture an image or recording at the time of sighting.
In these situations, the only available reference is the visual description of the bird, such as color, size, beak shape, or behavior.
AvesRAG was created to address this exact scenario, allowing bird identification based on text descriptions.

## ğŸ“Œ About the Project

The **AvesRAG Assistant** is an interactive intelligent assistant that aims to solve this problem by identifying birds based on user-provided descriptions. Using the **RAG (Retrieval-Augmented Generation)** technique, it searches for information in a custom database and returns **up to 3 candidate species** with summarized descriptions.

---
## ğŸ–¼ Interface Preview

![preview](docs/images/preview.png)

## ğŸ¯ Objectives

* Create an interactive tool for bird identification.
* Use RAG to combine structured search and text generation via LLM.
* Ensure the backend and pipeline are modular and easy to adapt.
* Collect user feedback to continuously improve results (In development).

## ğŸ“Š Database

The database used was created from:

* Integration of existing databases.
* Scraping from online sources.
* Data parameterization via LLM.

ğŸ“‚ Database Builder Repository: [rafaelladuarte/avesrag-dataset-builder](https://github.com/rafaelladuarte/avesrag-dataset-builder)

## ğŸ§© System Architecture

```mermaid
flowchart LR
    A[User] -->|Describe the bird| B[Streamlit UI]
    B --> | Params | D[MinSearch - Search Semantic + Vector]
    D --> | Retriviel Documents | E[LLM - Groq API]
    E --> | Verify Documents | B
    B --> | Validation of the Result | F[Feedback]
    F --> H[PostgresSQL]
    B --> G[Monitoring - In Developt]
    G --> I[Dashboard]
  
```

## âœ¨ Features

âœ… Data entry via form with validation. \
âœ… Optimized search with MinSearch (semantic + textual). \
âœ… Return of **up to 3 candidate species**. \
âœ… Automatic species summary with images.\
âœ…  User feedback collection\
ğŸ”„ Monitoring LLM usage - API.

## ğŸ”¬ Evaluation

### ğŸ” Retrieval

* **Tests performed**:
    * BM25 (textual)
    * Vector (embeddings)
    * Hybrid search (best result)

* **Result**: Hybrid search showed higher recall and precision for short descriptions.

### ğŸ§  LLM

* Different open-source models evaluated. * `llama-3.1-8b-instant`
* `gemma2-9b-it`
* `deepseek-r1-distill-llama-70b`
* Tested *zero-shot* vs *few-shot* prompts.
* **Result**: `llama-3.1-8b-instant` with *few-shot* had a better balance between cost and accuracy.

## ğŸ“Š Feedback and Monitoring (in development)

* User feedback collection (yes/no on answer usefulness).
* Storage in PostgreSQL
* Streamlit dashboard with metrics:
    * Number of queries
    * Most searched species
    * Accepted answer rate
    * Average response time

## ğŸ›  Technologies Used

| Category                | Tools                                                                                                             |
| ------------------------ | ----------------------------------------------------------------------------------------------------------------------- |
| **Linguagem**            | Python 3.11+                                                                                                            |
| **Framework Web**        | [Streamlit](https://streamlit.io/)                                                                                      |
| **LLM (Assistente)**     | `llama-3.1-8b-instant`                                                                                                  |
| **LLMs (Base de dados)** | `gemma2-9b-it`, `deepseek-r1-distill-llama-70b`, `llama-3.1-8b-instant` |
| **Backend de Busca**     | [MinSearch](https://github.com/alexeygrigorev/minsearch) *(adaptado)*                                                   |
| **API LLM**              | [Groq API](https://groq.com/)                                                                                           |
| **Processamento**        | pandas, numpy                                                                                                           |
| **Controle de VersÃ£o**   | Git + GitHub                                                                                                            |

## ğŸ“‚ Project Structure

```
ğŸ“¦ averag-assistant
â”œâ”€â”€ app.py                # Arquivo principal da aplicaÃ§Ã£o 
â”œâ”€â”€ dev.py                # Script auxiliar para desenvolvimento e testes locais
â”œâ”€â”€ docs/                 # DocumentaÃ§Ã£o do projeto
â”‚   â”œâ”€â”€ images/           # Imagens usadas na documentaÃ§Ã£o
â”‚   â””â”€â”€ notes/            # AnotaÃ§Ãµes, rascunhos e referÃªncias
â”œâ”€â”€ Pipfile               # DefiniÃ§Ãµes de dependÃªncias (Pipenv)
â”œâ”€â”€ Pipfile.lock          # Lockfile de dependÃªncias
â”œâ”€â”€ requirements.txt      # Alternativa de dependÃªncias para instalaÃ§Ã£o via pip
â”œâ”€â”€ README.md             # DocumentaÃ§Ã£o principal (PortuguÃªs)
â”œâ”€â”€ README_ENG.md         # DocumentaÃ§Ã£o principal (InglÃªs)
â”œâ”€â”€ .gitignore            # Arquivos e pastas ignorados pelo Git
â”œâ”€â”€ script/               # Scripts organizados por domÃ­nio
â”‚   â”œâ”€â”€ api/              # CÃ³digo relacionado a integraÃ§Ã£o com APIs externas
â”‚   â”œâ”€â”€ data/             # Base de dados utilizada para RAG em json
â”‚   â”œâ”€â”€ database/         # ConexÃ£o e operaÃ§Ãµes no banco de dados
â”‚   â”œâ”€â”€ notebooks/        # Jupyter Notebooks para anÃ¡lises e experimentos
â”‚   â”œâ”€â”€ services/        # Scripts da interface Streamlit
â”‚   â””â”€â”€ utils/           # FunÃ§Ãµes auxiliares e utilitÃ¡rios genÃ©ricos
â””â”€â”€ venv/                 

```

## âš™ï¸ Installation and Execution

### 1. Clone the repository

```bash
git clone https://github.com/usuario/avesrag-assistant.git
cd avesrag-assistant
```

### 2. Create the virtual environment and install dependencies

```bash
python -m venv venv
source venv/bin/activate # Linux/Mac
source venv\Scripts\activate # Windows
pip install -r requirements.txt
```

### 3. Configure environment variables

Create an `.env` file with:

```
GROQ_API_KEY1="yourkeyhere"
GROQ_API_KEY2="yourkeyhere"
POSTGRES_URL="yourkeyhere"
```

### 4. Run the application

```bash
streamlit run app.py
```

## ğŸ“ˆ Evaluation Criteria Met

* [x] Problem clearly described
* [x] Knowledge base + LLM in the flow
* [x] Evaluation of multiple retrieval flows
* [x] Evaluation of different prompts/models
* [x] Streamlit interface
* [ ] Automated ingestion via Python scripts
* [x] Monitoring with feedback
* [ ] Monitoring with use LLM  + dashboard
* [ ] Containerization with Docker
* [x] Reproducibility (instructions + requirements)

## ğŸ“ˆ Next Steps

* ğŸ”§ Adjust search weights and parameters in MinSearch
* ğŸ¦ Expand the database to more Brazilian species
* ğŸ§ª Create unit and integration tests
* ğŸ“Š Add query logging and monitoring

## ğŸ“œ License

Distributed under the MIT license. See the [LICENSE] file for more details.